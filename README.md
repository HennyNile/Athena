# Athena

Athena is a learned optimizer enhancer.

## File Organization

### Our order-centric plan explorer

`src/JOP/generate_dataset.py` is used to read the plans explored generated by the explorer implemented in PostgreSQL and then generate the training and testing dataset.

The modified PostgreSQL is open-sourced at [Athena_PG](https://github.com/NennyNile/Athena_PG).

### Our Tree-Mamba plan comparator

The code of the Tree-Mamba backbone is open-sourced at [TreeMamba](https://github.com/a858438680/TreeMamba).
The model design can be found in `src/LeroMamba/lero_model.py`.
The featurizer can be found in `src/LeroMamba/lero.py`.

### Our time-weighted loss function

The loss function can be found in the training script of our model, `src/LeroMamba/train.py`.

## Baselines

We directly reused the source code opened by Bao in our repository, which is `src\Bao\BaoForPostgreSQL`. We reimplemented its plan enumerator in `src\Bao\generate_dataset.py`.

We reimplemented Lero in `src\Lero`, including its plan enumeration method and learned plan comparator. The implementation of its plan enumerator requires modification of PG, which is also included in the [Athena_PG](https://github.com/NennyNile/Athena_PG).

## Experiments
The scirpt to evaluate the execution latency in the main experiment and ablation study is `scripts\run_experiments.py`. Parameters used in the training process can be found in that file. The plans will be selected and then executed. The executed plans will be recorded in the `records` to get the execution latency of workloads.